"val_WR"  = "WR",
"val_WO"  = "WO"))
values_long$value = unlist(values_long$value)
values_long <- values_long %>% filter(!is.infinite(value))
ggplot(values_long, aes(x = value, fill = method)) +
geom_density(alpha = 0.6, color = "black") +
geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
color = "black", lwd = 1) +
theme_minimal() +
labs(title = "Distribution des statistiques de test",
x = "Valeur", y = "Densité") +
scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
scale_fill_manual(values = c("orange",  "purple", "cyan")) +
annotate("text", x = 2.5, y = 1.6, label = paste("Étendue NB : ", étendue_NB), color = "orange", hjust = 1) +
annotate("text", x = 2.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
annotate("text", x = 2.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)
ggsave("Distrib_CsuupT.pdf", device = "pdf", path = "C:/Users/MASTERS TEMA Arthur/Documents/Comparaison-par-paire/plots" )
n_sim = 2000
n=200
nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()
results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
set.seed(s)
id=1:(2*n)
arm=rep(c("T","C"), each=200)
U = runif(2*n)
lambdaT = 0.1
kT = 2
Z = ifelse(arm == "T", 1, 0)
beta = 2
prob_T = 0.65
prob_C = 0.3
mean_T = 2
mean_C = 4
sd_T = 1
sd_C = 2
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
summary(Time_1[Z==0])
fup_censureT = round(rweibull(2*n, shape = 3, scale =10),3)
summary(fup_censureT)
Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)
Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1
Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)
stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)
data1=rbind(dataT,dataC)
summT = summary.data.frame(dataT)
min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))
nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)
nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)
median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))
max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))
summC = summary.data.frame(dataC)
min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))
median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))
max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))
censure_rateT=sum(dataT$Delta_1==1)/n
censure_rateC=sum(dataC$Delta_1==1)/n
data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )
result =
win.stat(
data = data,
ep_type = c("tte", "binary", "continuous"),
stratum.weight = "equal",
tau = c(1,0,1),
arm.name = c("T", "C"),
alpha = 0.05,
digit = 3,
pvalue = "two-sided",
priority = c(3,2,1),
summary.print = FALSE
)
win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = 4*2500-(win_edp3+loose_edp3)
win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp3-(loose_edp2+win_edp2)
win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=tie_edp2-sum(win_edp1+loose_edp1)
count = count + 1
write.table(c(count), file="../output.txt", append = T, col.names = F)
val_NB = result$Win_statistic$Net_Benefit[1]
val_WR  = result$Win_statistic$Win_Ratio[1]
val_WO  = result$Win_statistic$Win_Odds[1]
p_val_NB = result$p_value[2]
p_val_WR  = result$p_value[1]
p_val_WO  = result$p_value[3]
return(unname(c(val_NB,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_NB, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time
results_df = as.data.frame(results)
min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))
max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))
median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))
min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))
max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))
median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))
nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))
nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))
censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))
dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_3_C (tte)", "Y_1_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_3_T (tte)", "Y_1_T (continue)")
df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))
p_valNB = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]
nb_pval_NB = sum(p_valNB< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)
colnames(df2)=c(" ","C", "T")
NB=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])
quantileNB_lwr=quantile(NB, 0.025)
quantileNB_upr=quantile(NB, 0.975)
étendue_NB= round(quantileNB_upr - quantileNB_lwr,4)
quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)
quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)
Win   = round(c(mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))
Loose = round(c(mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))
Tie   = round(c(mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,6])) ))
df3 = data.frame(
row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
Win   = Win,
Loose = Loose,
Tie   = Tie,
WR = round(Win/Loose,5),
WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
NB = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_NB = paste("probabilité d'avoir des p-valeur < 0.05 pour la NB: ", nb_pval_NB/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))
vlines = data.frame(
method = c("NB", "WR", "WO"),
intercept = c(0, 1, 1),
linetype_label = "Hypothèse H0")
val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_NB","val_WR","val_WO")
summ_val5_2_1=summary(val)
values_long = val %>%
select(starts_with("val_")) %>%
pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
mutate(method = recode(method,
"val_NB" = "NB",
"val_WR"  = "WR",
"val_WO"  = "WO"))
values_long$value = unlist(values_long$value)
values_long <- values_long %>% filter(!is.infinite(value))
ggplot(values_long, aes(x = value, fill = method)) +
geom_density(alpha = 0.6, color = "black") +
geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
color = "black", lwd = 1) +
theme_minimal() +
labs(title = "Distribution des statistiques de test",
x = "Valeur", y = "Densité") +
scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
scale_fill_manual(values = c("orange",  "purple", "cyan")) +
annotate("text", x = 1.5, y = 1.6, label = paste("Étendue NB : ", étendue_NB), color = "orange", hjust = 1) +
annotate("text", x = 1.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
annotate("text", x = 1.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)
ggsave("order_change.pdf", device="pdf")
n_sim = 2000
n=200
nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()
results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
set.seed(s)
id=1:(2*n)
arm=rep(c("T","C"), each=200)
prob_T = 0.65
prob_C = 0.3
mean_T = 2
mean_C = 4
sd_T = 1
sd_C = 2
U = runif(2*n)
lambdaT = 0.5
kT = 5
Z = ifelse(arm == "T", 1, 0)
beta = -1
Time_1 = round((((1/(1-U)-1)*(1/lambdaT))^(1/kT)*exp(Z*beta)), 3)
fup_censureT = round(rweibull(2*n, shape = 2, scale =3),3)
Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)
Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1
Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)
stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)
data1=rbind(dataT,dataC)
summT = summary.data.frame(dataT)
min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))
nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)
nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)
median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))
max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))
summC = summary.data.frame(dataC)
min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))
median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))
max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))
censure_rateT=sum(dataT$Delta_1==1)/n
censure_rateC=sum(dataC$Delta_1==1)/n
data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )
result =
win.stat(
data = data,
ep_type = c("tte", "binary", "continuous"),
stratum.weight = "equal",
tau = c(1,0,1),
arm.name = c("T", "C"),
alpha = 0.05,
digit = 3,
pvalue = "two-sided",
priority = c(3,2,1),
summary.print = FALSE
)
win_edp3 = sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp3 = 4*2500-(win_edp3+loose_edp3)
win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp3-(loose_edp2+win_edp2)
win_edp1=sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp1=tie_edp2-sum(win_edp1+loose_edp1)
count = count + 1
write.table(c(count), file="../output.txt", append = T, col.names = F)
val_NB = result$Win_statistic$Net_Benefit[1]
val_WR  = result$Win_statistic$Win_Ratio[1]
val_WO  = result$Win_statistic$Win_Odds[1]
p_val_NB = result$p_value[2]
p_val_WR  = result$p_value[1]
p_val_WO  = result$p_value[3]
return(unname(c(val_NB,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_NB, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time
results_df = as.data.frame(results)
min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))
max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))
median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))
min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))
max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))
median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))
nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))
nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))
censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))
dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_3_C (tte)", "Y_1_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_3_T (tte)", "Y_1_T (continue)")
df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))
p_valNB = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]
nb_pval_NB = sum(p_valNB< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)
colnames(df2)=c(" ","C", "T")
NB=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])
quantileNB_lwr=quantile(NB, 0.025)
quantileNB_upr=quantile(NB, 0.975)
étendue_NB= round(quantileNB_upr - quantileNB_lwr,4)
quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)
quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)
Win   = round(c(mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))
Loose = round(c(mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))
Tie   = round(c(mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,12])) ))
df3 = data.frame(
row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
Win   = Win,
Loose = Loose,
Tie   = Tie,
WR = round(Win/Loose,5),
WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
NB = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_NB = paste("probabilité d'avoir des p-valeur < 0.05 pour la NB: ", nb_pval_NB/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))
vlines = data.frame(
method = c("NB", "WR", "WO"),
intercept = c(0, 1, 1),
linetype_label = "Hypothèse H0")
val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_NB","val_WR","val_WO")
summ_val5_2_2=summary(val)
values_long = val %>%
select(starts_with("val_")) %>%
pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
mutate(method = recode(method,
"val_NB" = "NB",
"val_WR"  = "WR",
"val_WO"  = "WO"))
values_long$value = unlist(values_long$value)
values_long <- values_long %>% filter(!is.infinite(value))
ggplot(values_long, aes(x = value, fill = method)) +
geom_density(alpha = 0.6, color = "black") +
geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
color = "black", lwd = 1) +
theme_minimal() +
labs(title = "Distribution des statistiques de test",
x = "Valeur", y = "Densité") +
scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
scale_fill_manual(values = c("orange",  "purple", "cyan")) +
annotate("text", x = 1.5, y = 1.6, label = paste("Étendue NB : ", étendue_NB), color = "orange", hjust = 1) +
annotate("text", x = 1.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
annotate("text", x = 1.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)
ggsave("AFT_order_change.pdf", device="pdf")
setwd("C:/Users/MASTERS TEMA Arthur/Documents/Comparaison-par-paire/R/BICAR-ICU")
data=readxl::read_xlsx("Export-20250617.xlsx")
data_epur=data[,c(1, 3, 6, 7,8, 62, 69, 76, 78)]
colnames(data_epur)=c("id","arm", "SEPSIS_ON", "AGE_RANDO", "AKIN", "Décès", "Dialyse", "Vaso_free_day", "Ventil_free_day")
New_data=data.frame(id=data_epur[,1], arm = data_epur[,2], Y_1= data_epur[,6],Y_2=data_epur[,7], Y_3 = data_epur[,9], Y_4 = data_epur[,8] )
str(New_data)
New_data[,3]=="Non"
New_data[,3]=ifelse(New_data[,3]=="Non", 0, 1)
New_data[,4]= ifelse(New_data[,4]=="Non", 0, 1)
str(New_data)
result =
win.stat(
data = New_data,
ep_type = c("binary", "binary", "continuous",  "continuous" ),
stratum.weight = "unstratified",
tau = c(0,0,0,0),
arm.name = c("Bras B", "Bras A"),
alpha = 0.05,
digit = 3,
pvalue = "two-sided",
priority = c(1,2,3,4),
np_direction = c("smaller","smaller","larger","larger"),
summary.print = TRUE
)
library(WINS)
result =
win.stat(
data = New_data,
ep_type = c("binary", "binary", "continuous",  "continuous" ),
stratum.weight = "unstratified",
tau = c(0,0,0,0),
arm.name = c("Bras B", "Bras A"),
alpha = 0.05,
digit = 3,
pvalue = "two-sided",
priority = c(1,2,3,4),
np_direction = c("smaller","smaller","larger","larger"),
summary.print = TRUE
)
is.na(New_data)
sum(is.na(New_data)==TRUE)
View(data_epur)
which(is.na(New_data)==TRUE)
which(is.na(data_epur)==TRUE)
if(is.na(New_data==TRUE)){New_data[which(is.na(New_data==TRUE)),]==0}
View(New_data)
if(is.na(New_data==TRUE)){New_data=New_data[-which(is.na(New_data==TRUE)),]==0}
New_data <- New_data[!is.na(New_data$Vaso_free_day), ]
sum(is.na(New_data)==TRUE)
result =
win.stat(
data = New_data,
ep_type = c("binary", "binary", "continuous",  "continuous" ),
stratum.weight = "unstratified",
tau = c(0,0,0,0),
arm.name = c("Bras B", "Bras A"),
alpha = 0.05,
digit = 3,
pvalue = "two-sided",
priority = c(1,2,3,4),
np_direction = c("smaller","smaller","larger","larger"),
summary.print = TRUE
)
New_data=data.frame(id=data_epur[,1], arm = data_epur[,2], Y_1= data_epur[,6],Y_2=data_epur[,7], Y_3 = data_epur[,9], Y_4 = data_epur[,8] )
New_data[,3]=ifelse(New_data[,3]=="Non", 0, 1)
New_data[,4]= ifelse(New_data[,4]=="Non", 0, 1)
New_data <- New_data[!is.na(New_data$Vaso_free_day), ]
result =
win.stat(
data = New_data,
ep_type = c("binary", "binary", "continuous",  "continuous" ),
stratum.weight = "unstratified",
tau = c(0,0,0,0),
arm.name = c("Bras B", "Bras A"),
alpha = 0.05,
digit = 3,
pvalue = "two-sided",
priority = c(1,2,3,4),
np_direction = c("smaller","smaller","larger","larger"),
summary.print = TRUE
)
New_data
names(New_data)
str(New_data)
result =
win.stat(
data = New_data,
ep_type = c("binary", "binary", "continuous",  "continuous" ),
stratum.weight = "unstratified",
tau = c(0,0,0,0),
arm.name = c("Bras B", "Bras A"),
alpha = 0.05,
digit = 3,
pvalue = "two-sided",
priority = c(1,2,3,4),
np_direction = c("smaller","smaller","larger","larger"),
summary.print = TRUE
)
result =
win.stat(
data = New_data,
ep_type = c("binary", "binary", "continuous",  "continuous" ),
stratum.weight = "unstratified",
tau = c(0,0,0,0),
arm.name = c("BRAS B", "BRAS A"),
alpha = 0.05,
digit = 3,
pvalue = "two-sided",
priority = c(1,2,3,4),
np_direction = c("smaller","smaller","larger","larger"),
summary.print = TRUE
)
setwd("C:/Users/MASTERS TEMA Arthur/Documents/Comparaison-par-paire/R/BICAR-ICU")
library(WINS)
data=readxl::read_xlsx("Export-20250617.xlsx")
data_epur=data[,c(1, 3, 6, 7,8, 62, 69, 76, 78)]
colnames(data_epur)=c("id","arm", "SEPSIS_ON", "AGE_RANDO", "AKIN", "Décès", "Dialyse", "Vaso_free_day", "Ventil_free_day")
New_data=data.frame(id=data_epur[,1], arm = data_epur[,2], Y_1= data_epur[,6],Y_2=data_epur[,7], Y_3 = data_epur[,9], Y_4 = data_epur[,8] )
New_data[,3]=ifelse(New_data[,3]=="Non", 0, 1)
New_data[,4]= ifelse(New_data[,4]=="Non", 0, 1)
New_data <- New_data[!is.na(New_data$Vaso_free_day), ]
names(New_data)
str(New_data)
result =
win.stat(
data = New_data,
ep_type = c("binary", "binary", "continuous",  "continuous" ),
stratum.weight = "unstratified",
tau = c(0,0,0,0),
arm.name = c("BRAS B", "BRAS A"),
alpha = 0.05,
digit = 3,
pvalue = "two-sided",
priority = c(1,2,3,4),
np_direction = c("smaller","smaller","larger","larger"),
summary.print = TRUE
)
