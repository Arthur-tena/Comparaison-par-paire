---
title: "Simulations2"
author: "Arthur Tena"
date: "2025-05-15"
output:
  pdf_document:
    latex_engine: pdflatex
    extra_dependencies: ['subcaption', 'caption']
    toc: true
---

```{r setup, include=FALSE, echo = FALSE}
knitr::opts_chunk$set(echo = FALSE)
knitr::opts_knit$set(root.dir = "~/comparaison-par-paire/R", fig.subcap = c("Sous-figure 1", "Sous-figure 2"))
library(dplyr)
library(purrr)
library(ggplot2)
library(tidyr)

library(survival)

library(WINS)
library(knitr)
library(gridExtra)
library(grid)


library(doParallel)
library(parallel)
library(foreach)
source("fonctions.R")
```

\newpage

Soit $U \sim \mathcal{U}([0,1])$, on simulera nos lois tte avec HR constant comme ceci :

$$X = \frac{-\log(1 - U)}{\lambda \, \left(e^{\beta Z}\right)^{1/k}}$$
Les paramètres $\lambda$, $k$ et la loi de la censure seront précisés. La covariable $Z$ correspond au traitement, Z = 1 si le patient est dans le groupe traité et 0 sinon.

# Scénario 1 : $T \sim C$

Paramètres :

- tte :

  $\lambda = 1$, $k = 0.5$, $\beta = 0$, la censure sera une distribution $\mathcal{W}(1,2)$
 
- Continue :

  $\mathcal{N}_T(3,2)$ ; $\mathcal{N}_C(3,2)$
  
- Binaire :

  $\mathcal{B}_T(0.5)$ ; $\mathcal{B}_C(0.5)$ 
 
 
## tau = 0

```{r, echo=FALSE, warning=TRUE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  
U = runif(2*n) 

lambdaT = 1
kT = 0.5


Z = ifelse(arm == "T", 1, 0)
beta = -0

prob_T = 0.5
prob_C = 0.5

mean_T = 3
mean_C = 3
sd_T = 2
sd_C = 2

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 1, scale =3),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(0,0,0),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp1-(loose_edp2+win_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp2-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")

val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val1_1=summary(val)




 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 2, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 2, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 2, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

ggsave("TeqC_tau0.pdf", device = "pdf")

```

```{r, echo=FALSE}
summary_df1_1 <- summ_val1_1 %>% as.data.frame()
summary_df1_1 <- summary_df1_1 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

summary_df1_1
```


## tau = 2

```{r, echo=FALSE, warning=TRUE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=n)
  
U = runif(2*n) 

lambdaT = 1
kT = 0.5


Z = ifelse(arm == "T", 1, 0)
beta = -0

prob_T = 0.5
prob_C = 0.5

mean_T = 3
mean_C = 3
sd_T = 2
sd_C = 2

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 1, scale =3),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 


data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=4*2500-(win_edp2+loose_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = 4*2500-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)

  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]

  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val1_2=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 2, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 2, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 2, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

ggsave("TeqC_tau2.pdf", device = "pdf")

```

L'étendue est plus importante pour le **WR** que pour le **WO** même avec des distributions similaire, il voudrait mieux prioriser le **WO** ou la **GPC** suivant les besoins.

```{r, echo=FALSE}
summary_df1_2 <- summ_val1_2 %>% as.data.frame()
summary_df1_2 <- summary_df1_2 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

summary_df1_2
```

On ne remarque pas de grosse différence au niveau de la **GPC**. Le **WR** est plus étendu, on le voit par rapport  au min et au max mais les médianes sont proche. Le **WO** n'a pas beaucoup bougé non plus 

## Outcome discrèt de Poisson

La distribution de Poisson est de paramètre $\lambda = 3$, le seuil est de 2. Les distributions des autres outcomes ne changent pas : $\mathcal{B}_T(0.5)$ ; $\mathcal{B}_C(0.5)$ .

```{r, echo=FALSE, warning=TRUE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
  
id=1:(2*n) 
arm=rep(c("T","C"), each=n)
  
U = runif(2*n) 

lambdaT = 1
kT = 0.5


Z = ifelse(arm == "T", 1, 0)
beta = -0

prob_T = 0.5
prob_C = 0.5

lambda_T = 3
lambda_C = 3
  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 1, scale =3),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= abs(gener_poisson(lambda = lambda_T))
Y_3_C= abs(gener_poisson(lambda = lambda_C))

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
colnames(dataT)= c("Y_1", "Delta_1", "Y_2", "Y_3", "stratum")
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)
colnames(dataC)= c("Y_1", "Delta_1", "Y_2", "Y_3", "stratum")

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 


data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp1-(win_edp2+loose_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp2-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)

  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]

  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]), na.rm = T)

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]), na.rm = T)

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]), na.rm = T)

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]), na.rm = T)

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]), na.rm = T)

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]), na.rm = T)

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (poisson)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (poisson)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val1_3=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 2, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 2, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 2, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

ggsave("TeqC_poisson.pdf", device = "pdf")


```

```{r, echo=FALSE}
summary_df1_3 <- summ_val1_3 %>% as.data.frame()
summary_df1_3 <- summary_df1_3 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

summary_df1_3

```

Très peu de différence entre l'outcome continue normal et de poisson. 

## Outcome binaire en premier

```{r, echo=FALSE, warning=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  
U = runif(2*n) 

lambdaT = 1
kT = 0.5


Z = ifelse(arm == "T", 1, 0)
beta = -0

prob_T = 0.5
prob_C = 0.5

mean_T = 3
mean_C = 3
sd_T = 2
sd_C = 2

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 1, scale =3),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(2,1,3),
    summary.print = FALSE
  )



win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=4*2500-(loose_edp2+win_edp2)

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=tie_edp2-sum(win_edp1+loose_edp1)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp1-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
      return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_2_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_2_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,8])), mean(as.numeric(results_df[,5])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val1_4=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 2, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 2, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 2, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

ggsave("TeqC_tau2_binaire.pdf", device = "pdf")

```

Très peu de différence entre les étendues lorsque l'outcome tte est premier ou lorsque c'est l'outcome binaire. 

```{r, echo = FALSE,  }
df= data.frame(row.names = c("WO", "WR", "GPC"), c(0.4312, 0.5958, 0.2121), c(0.4393, 0.61, 0.2156))
colnames(df) = c( "Oucome tte", "Outcome binaire")
kable(df, caption = "Comparaison de l'étendue entre les deux critères lorsque le seuil vaut 0")
```


```{r, echo=FALSE}
summary_df1_4 <- summ_val1_4 %>% as.data.frame()
summary_df1_4 <- summary_df1_4 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

summary_df1_4
```

\newpage 

# Scénario 2 : $T \gg C$

Paramètres :

- tte :

  $\lambda = 1$, $k = 2$, $\beta = -2$, la censure sera une distribution $\mathcal{W}(1,3)$
 
- Continue :

  $\mathcal{N}_T(3,2)$ ; $\mathcal{N}_C(2,2)$
  
- Binaire :

  $\mathcal{B}_T(0.65)$ ; $\mathcal{B}_C(0.3)$

## tau = 0

```{r, echo=FALSE, warning=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  
U = runif(2*n) 

lambdaT = 1
kT = 2


Z = ifelse(arm == "T", 1, 0)
beta = -2

prob_T = 0.65
prob_C = 0.3

mean_T = 3
mean_C = 2
sd_T = 2
sd_C = 2

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 1, scale =3),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum) 
 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(0,0,0),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp1-(loose_edp2+win_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp2-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
      return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val2_1=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)


```

```{r, echo=FALSE}
summary_df2_1 <- summ_val2_1 %>% as.data.frame()
summary_df2_1 <- summary_df2_1 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

summary_df2_1
```


## tau = 2

```{r, echo=FALSE, warning=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  
U = runif(2*n) 

lambdaT = 1
kT = 2


Z = ifelse(arm == "T", 1, 0)
beta = -2

prob_T = 0.65
prob_C = 0.3

mean_T = 3
mean_C = 2
sd_T = 2
sd_C = 2

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 1, scale =3),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp1-(loose_edp2+win_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp2-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val2_2=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

ggsave("TsupC_tau2.pdf", device = "pdf")

```

Grosse étendue pour le **WR** valant 2.33 alors qu'elle est aux alentours de 1.2 pour le **WO** et la **GPC** par transformation. On y voit des valeurs plus disparates le premier endpoint est assez parlant, on y voit une valeur de 3.6 pour le WR, on pourait penser que la p-valeur est très faible alors que pour le **WO** et la **GPC** la p-valeur devrait être élevée. 

Une petite différence est notable entre le moment où l'outcome principal est tte ou binaire

```{r, echo = FALSE,  }
df= data.frame(row.names = c("WO", "WR", "GPC"), c(1.1513, 2.3298, 0.178), c(1.2054, 2.4251, 0.1844))
colnames(df) = c( "Oucome tte", "Outcome binaire")
kable(df, caption = "Comparaison de l'étendue entre les deux critères lorsque le seuil vaut 2")
```

```{r, echo=FALSE}
summary_df2_2 <- summ_val2_2 %>% as.data.frame()
summary_df2_2 <- summary_df2_2 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

summary_df2_2
```


## Outcome discret de poisson

Ici, on aura un seuil de 2 et les 2 distribution de poisson seront les suivantes :

$$ \mathcal{P}_T(3) \quad ; \quad \mathcal{P}_C(1) $$

Les autres distributions seront identiques : 

$\mathcal{B}_T(0.65)$ ; $\mathcal{B}_C(0.3)$ ; $\mathcal{N}_T(3,2)$ ; $\mathcal{N}_C(2,2)$

```{r, echo=FALSE, warning=TRUE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=n)
  
U = runif(2*n) 

lambdaT = 1
kT = 2


Z = ifelse(arm == "T", 1, 0)
beta = -2

prob_T = 0.65
prob_C = 0.3

lambda_T = 3
lambda_C = 1
  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 1, scale =3),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_poisson(lambda = lambda_T)
Y_3_C= gener_poisson(lambda = lambda_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
colnames(dataT)= c("Y_1", "Delta_1", "Y_2", "Y_3", "stratum")
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)
colnames(dataC)= c("Y_1", "Delta_1", "Y_2", "Y_3", "stratum")

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 


data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=4*2500-(win_edp2+loose_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = 4*2500-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)

  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]

  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]), na.rm = T)

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]), na.rm = T)

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]), na.rm = T)

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]), na.rm = T)

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]), na.rm = T)

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]), na.rm = T)

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]), na.rm = T)

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]), na.rm = T)

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (poisson)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (poisson)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val2_3=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)


```

```{r, echo=FALSE}
summary_df2_3 <- summ_val2_3 %>% as.data.frame()
summary_df2_3 <- summary_df2_3 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

summary_df2_3
```


## Outcome binaire en premier

```{r, echo=FALSE, warning=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  
U = runif(2*n) 

lambdaT = 1
kT = 2


Z = ifelse(arm == "T", 1, 0)
beta = -2

prob_T = 0.65
prob_C = 0.3

mean_T = 3
mean_C = 2
sd_T = 2
sd_C = 2

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 1, scale =3),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(2,1,3),
    summary.print = FALSE
  )



win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=4*2500-(loose_edp2+win_edp2)

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=tie_edp2-sum(win_edp1+loose_edp1)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp1-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
   return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_2_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_2_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,5])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,5])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val2_4=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

ggsave("TsupC_tau2_binaire.pdf", device = "pdf")

```

```{r, echo=FALSE}
summary_df2_4 <- summ_val2_4 %>% as.data.frame()
summary_df2_4 <- summary_df2_4 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

g1 <- tableGrob(summary_df2_4)
g2 <- tableGrob(summary_df2_2[,-1])

# Ajoute les titres au-dessus des tableaux
title1 <- textGrob("Résumé - Cox, tau=2", gp = gpar(fontsize = 12, fontface = "bold"))
title2 <- textGrob("Résumé - Cox, binaire", gp = gpar(fontsize = 12, fontface = "bold"))

# Combine titre + tableau pour chaque colonne
g1_full <- arrangeGrob(title1, g1, ncol = 1, heights = c(0.2, 1))
g2_full <- arrangeGrob(title2, g2, ncol = 1, heights = c(0.2, 1))

# Affiche côte à côte
space <- nullGrob()  # Affichage avec espace 
grid.arrange(g1_full, space, g2_full, ncol = 3, widths = c(1, 0.2, 1))
```

\newpage



# Modèle avec les HR non-constant

On travaille avec un modèle AFT où les HR ne sont pas constant. Le seuil $\tau$ vaut 2 pour les outcomes 1 (tte) et 3 (continue). La formule pour de simulation pour le modèle AFT est la suivante : 

$$(\frac{1}{1-U}-1) \times \lambda^{-1/k} \times e^{Z \beta} $$

Où $U \sim \mathcal{U}([0,1])$, Z la covariable valant 1 si le patient suit le traitement et 0 s'il suit le contrôle. Les paramètres $\lambda$ et $k$ vaudront respectivement 0.12 et 0.9, et $\beta = 2.5$.

Les distributions des outcomes binaire et continue sont les suivantes : 

$$ \mathcal{B}_T(0.65) \quad ; \quad \mathcal{B}_C(0.3) \quad ; \quad \mathcal{N}_T(3,2) \quad ; \quad \mathcal{N}_C(2,2) $$

## tau = 0

```{r, echo=FALSE, warning=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)


prob_T = 0.65
prob_C = 0.3

mean_T = 3
mean_C = 2
sd_T = 2
sd_C = 2

U = runif(2*n) 
lambdaT = 0.12
kT = 0.9


Z = ifelse(arm == "T", 1, 0)
beta = 2.5


Time_1 = round((((1/(1-U)-1)*(1/lambdaT))^(1/kT)*exp(Z*beta)), 3)
fup_censureT = round(rweibull(2*n, shape = 1.5, scale =5.5),3)

Time_T = pmin(Time_1, fup_censureT)

deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(0,0,0),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp1-(loose_edp2+win_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp2-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val3_1=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)


```

On remarque, en comparant avec le scénario 2 où les distribution continue et binaire ont les même lois que dans cette section que le résultat est similaire par rapport aux p-valeurs malgré le fait qu'ici le premier endpoint ne départage pas le groupe traité du groupe contrôle. 

```{r, echo=FALSE}
summary_df3_1 <- summ_val3_1 %>% as.data.frame()
summary_df3_1 <- summary_df3_1 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

g1 <- tableGrob(summary_df3_1)
g2 <- tableGrob(summary_df2_1[,-1])

# Ajoute les titres au-dessus des tableaux
title1 <- textGrob("Résumé - AFT, tau=0", gp = gpar(fontsize = 12, fontface = "bold"))
title2 <- textGrob("Résumé - Cox, tau=0", gp = gpar(fontsize = 12, fontface = "bold"))

# Combine titre + tableau pour chaque colonne
g1_full <- arrangeGrob(title1, g1, ncol = 1, heights = c(0.2, 1))
g2_full <- arrangeGrob(title2, g2, ncol = 1, heights = c(0.2, 1))

space <- nullGrob()

# Affichage avec espace
grid.arrange(g1_full, space, g2_full, ncol = 3, widths = c(1, 0.2, 1))
```


## tau = 2

```{r, echo=FALSE, warning=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  

prob_T = 0.65
prob_C = 0.3

mean_T = 3
mean_C = 2
sd_T = 2
sd_C = 2


U = runif(2*n) 
lambdaT = 0.12
kT = 0.9


Z = ifelse(arm == "T", 1, 0)
beta = 2.5


Time_1 = round((((1/(1-U)-1)*(1/lambdaT))^(1/kT)*exp(Z*beta)), 3)
fup_censureT = round(rweibull(2*n, shape = 1.5, scale =5.5),3)


Time_T = pmin(Time_1, fup_censureT)

deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp1-(loose_edp2+win_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp2-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val3_2=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

ggsave("AFT_tau2.pdf", device = "pdf")

```

```{r, echo=FALSE}
summary_df3_2 <- summ_val3_2 %>% as.data.frame()
summary_df3_2 <- summary_df3_2 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

g1 <- tableGrob(summary_df3_2)
g2 <- tableGrob(summary_df2_2[,-1])

# Ajoute les titres au-dessus des tableaux
title1 <- textGrob("Résumé - AFT, tau=2", gp = gpar(fontsize = 12, fontface = "bold"))
title2 <- textGrob("Résumé - Cox, tau=2", gp = gpar(fontsize = 12, fontface = "bold"))

# Combine titre + tableau pour chaque colonne
g1_full <- arrangeGrob(title1, g1, ncol = 1, heights = c(0.2, 1))
g2_full <- arrangeGrob(title2, g2, ncol = 1, heights = c(0.2, 1))

# Affiche côte à côte
space <- nullGrob()  # Affichage avec espace 
grid.arrange(g1_full, space, g2_full, ncol = 3, widths = c(1, 0.2, 1))
```

\newpage




# Distribution très différente 

## tau = 0

```{r, echo=FALSE, warning=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  
U = runif(2*n) 

lambdaT = 1
kT = 2


Z = ifelse(arm == "T", 1, 0)
beta = -2

prob_T = 0.7
prob_C = 0.3

mean_T = 3
mean_C = 1.3
sd_T = 2
sd_C = 1

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 1, scale =3),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp1-(loose_edp2+win_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp2-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
   return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val4_1=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan"))+
  annotate("text", x = 7.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 7.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 7.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)


```

```{r, echo=FALSE}
summary_df4_1 <- summ_val4_1 %>% as.data.frame()
summary_df4_1 <- summary_df4_1 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

summary_df4_1
```


## tau = 2

```{r, echo=FALSE, warning=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  
U = runif(2*n) 

lambdaT = 0.01
kT = 5


Z = ifelse(arm == "T", 1, 0)
beta = -10

prob_T = 0.7
prob_C = 0.3

mean_T = 3
mean_C = 1.3
sd_T = 2
sd_C = 1

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 2, scale =1),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp1-(loose_edp2+win_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp2-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
    return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val4_2=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan"))+
  annotate("text", x = 9.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 9.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 9.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

ggsave("distrib_diff_tau2.pdf", device = "pdf")

```


```{r, echo=FALSE}
summary_df4_2 <- summ_val4_2 %>% as.data.frame()
summary_df4_2 <- summary_df4_2 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

summary_df4_2
```


\newpage



# Distribution avec des résultats différents suivant les outcomes 

Dans cette partie, nous allons dans un premier temps choisir des distributions de façon à ce que l'outcome principal soit en faveur de T et les 2 autres en faveur de C. 

Dans un second temps nous ferons varier l'ordre des outcome pour voir s'il y a des différences significatives entre les statistiques en fonction de leur ordre.

Dans tous ces cas, les distributions continues seront des lois normales dont les paramètres seront précisés. Les seuils $\tau$ seront toujours égaux à 2 pour les distributions continue et tte.

## Différents scénario dans le même tableau de donnée

Les paramètres des distributions tte changeront et seront précisées mais les paramètres des 2 autres lois ne changeront pas et seront :

- Continue :

  $\mathcal{N}_T(2,1)$ ; $\mathcal{N}_C(4,2)$
  
- Binaire :

  $\mathcal{B}_T(0.65)$ ; $\mathcal{B}_C(0.3)$

### HR constant (modèle de Cox)

Ici, l'outcome binaire sera en faveur du traitement, l'outcome continue en faveur du contrôle et l'outcome principal tte sera beaucoup censuré avec des distributions plus ou moins en faveur du traitement.

La distribution tte sera de paramètre  :  $\lambda = 1$, $k = 2$, $\beta = -2$, la censure sera une distribution $\mathcal{W}(1,3)$



```{r, echo=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  
U = runif(2*n) 

lambdaT = 0.05
kT = 4



Z = ifelse(arm == "T", 1, 0)
beta = -3

prob_T = 0.65
prob_C = 0.3

mean_T = 2
mean_C = 4
sd_T = 1
sd_C = 2

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 3, scale =10),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(1,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp1-(loose_edp2+win_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp2-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)


colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val5_1_1=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

ggsave("Distrib_cont_C.pdf", device = "pdf", path = "C:/Users/MASTERS TEMA Arthur/Documents/Comparaison-par-paire/plots" )

```

```{r, echo=FALSE}
summary_df5_1_1 <- summ_val5_1_1 %>% as.data.frame()
summary_df5_1_1 <- summary_df5_1_1 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

g1 <- tableGrob(summary_df5_1_1)
g2 <- tableGrob(summary_df2_2[,-1])

# Ajoute les titres au-dessus des tableaux
title1 <- textGrob("Résumé - Cox, outcome continue C>>T, tau=2", gp = gpar(fontsize = 12, fontface = "bold"))
title2 <- textGrob("Résumé - Cox, tau=2", gp = gpar(fontsize = 12, fontface = "bold"))

# Combine titre + tableau pour chaque colonne
g1_full <- arrangeGrob(title1, g1, ncol = 1, heights = c(0.2, 1))
g2_full <- arrangeGrob(title2, g2, ncol = 1, heights = c(0.2, 1))

# Affiche côte à côte
space <- nullGrob() 
grid.arrange(g1_full, space, g2_full, ncol = 3, widths = c(1, 0.2, 1))
```

Ici, nous ferons la comparaison avec la section *Scénario 2 : $T \gg C$, 2- tau = 2* où la différence se fait sur la distribution continue. 
On remarque directement une grosse différence de valeur entre T et C pour l'outcome continue. Ce que l'on peut noter c'est qu'il y a moins de variation sur les 3 statistiques ce qui est d'autant plus criant sur le WR qui passe d'une étendue de 2.3298 lorsque nous sommes dans le cas où tous les outcome sont en faveur de T mais baisse à 1.1962 ici. 

Nous notons aussi que le max des **WR** ici est du 3.37 alors que cela corresponds à la médiane dans l'autre section et au max du **WO**.

On remarque bien  un fort effet de l'outcome continue sur le résultat. Il faudrait voir ce que cela donne en mettant cet outcome comme étant de prioritaire.

### HR non-constant (modèle AFT)

Ici les paramètres $\lambda$ et $k$ voudront respectivement 0.12 et 0.9, la loi de la censure sera une $\mathcal{W}(1.5,5.5)$.

```{r, echo=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)


prob_T = 0.65
prob_C = 0.3

mean_T = 2
mean_C = 4
sd_T = 1
sd_C = 2


U = runif(2*n) 
lambdaT = 0.12
kT = 0.9


Z = ifelse(arm == "T", 1, 0)
beta = 2.5


Time_1 = round((((1/(1-U)-1)*(1/lambdaT))^(1/kT)*exp(Z*beta)), 3)
fup_censureT = round(rweibull(2*n, shape = 1.5, scale =5.5),3)


Time_T = pmin(Time_1, fup_censureT)

deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(1,2,3),
    summary.print = FALSE
  )

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=4*2500-sum(win_edp1+loose_edp1)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp1-(loose_edp2+win_edp2)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp2-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val5_1_2=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

```

```{r, echo=FALSE}
summary_df5_1_2 <- summ_val5_1_2 %>% as.data.frame()
summary_df5_1_2 <- summary_df5_1_2 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

g1 <- tableGrob(summary_df5_1_2)
g2 <- tableGrob(summary_df3_2[,-1])

# Ajoute les titres au-dessus des tableaux
title1 <- textGrob("Résumé - AFT, tau=2, outcome continue C>>T", gp = gpar(fontsize = 12, fontface = "bold"))
title2 <- textGrob("Résumé - AFT, tau=2", gp = gpar(fontsize = 12, fontface = "bold"))

# Combine titre + tableau pour chaque colonne
g1_full <- arrangeGrob(title1, g1, ncol = 1, heights = c(0.2, 1))
g2_full <- arrangeGrob(title2, g2, ncol = 1, heights = c(0.2, 1))

# Affiche côte à côte
space <- nullGrob() 
grid.arrange(g1_full, space, g2_full, ncol = 3, widths = c(1, 0.2, 1))
```

On remarque légèrement plus de variation dans le modèle AFT que dans le modèle de Cox.

### Très extrême 

Ici nous avons un endpoint principal en faveur du groupe traité, dont les distributions sont $\mathcal{B}_T(0.65)$ ; $\mathcal{B}_C(0.3)$ alors que les 2 autres endpoint sont en faveur du groupe contrôle, la distribution tte est la même que précédemment mais avec $\beta=2$ pour favorisé le groupe C alors que la distribution continue est bien en faveur du contrôle : $\mathcal{N}_T(3,1) \quad ; \quad \mathcal{N}_C(4,2)$ .

```{r, echo=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  
U = runif(2*n) 
lambdaT = 0.05
kT = 4
fup_censureT = round(rweibull(2*n, shape = 3, scale =8),3)

Z = ifelse(arm == "T", 1, 0)
beta = 4

prob_T = 0.65
prob_C = 0.3

mean_T = 2
mean_C = 4
sd_T = 1
sd_C = 2

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 3, scale =10),3)



Time_T = pmin(Time_1, fup_censureT)

deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(1,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(2,1,3),
    summary.print = FALSE
  )

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=4*2500-(loose_edp2+win_edp2)

win_edp1=sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp1=tie_edp2-sum(win_edp1+loose_edp1)

win_edp3 = sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp3 = tie_edp1-(win_edp3+loose_edp3)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_1_C (tte)", "Y_3_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_1_T (tte)", "Y_3_T (Continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,8])), mean(as.numeric(results_df[,5])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val5_1_3=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

ggsave("Distrib_CsuupT.pdf", device = "pdf", path = "C:/Users/MASTERS TEMA Arthur/Documents/Comparaison-par-paire/plots" )

```

```{r, echo=FALSE}
summary_df5_1_3 <- summ_val5_1_3 %>% as.data.frame()
summary_df5_1_3 <- summary_df5_1_3 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

g1 <- tableGrob(summary_df5_1_3)
g2 <- tableGrob(summary_df5_1_1[,-1])

# Ajoute les titres au-dessus des tableaux
title1 <- textGrob("Résumé - Cox, tau=2, double otc C>>T", gp = gpar(fontsize = 12, fontface = "bold"))
title2 <- textGrob("Résumé - Cox, tau=2, otc continue C>>T", gp = gpar(fontsize = 12, fontface = "bold"))

# Combine titre + tableau pour chaque colonne
g1_full <- arrangeGrob(title1, g1, ncol = 1, heights = c(0.2, 1))
g2_full <- arrangeGrob(title2, g2, ncol = 1, heights = c(0.2, 1))

# Affiche côte à côte
space <- nullGrob() 
grid.arrange(g1_full, space, g2_full, ncol = 3, widths = c(1, 0.2, 1))
```


## Variation des ordres 

Dans un premier temps, nous avons vu des outcomes tte et binaire en outcome principaux, maintenant, nous allons voir l'outcome continue étant en faveur du contrôle comme outcome principal d'abord en simulant nos données tte suivant un modèle de Cox et ensuite avec un modèle AFT où les HR ne seront pas constant. 

### HR constant 

Les distributions seront les suivantes : 

- tte :

  $\lambda = 1$, $k = 2$, $\beta = -2$, la censure sera une distribution $\mathcal{W}(1,3)$
 
- Continue :

  $\mathcal{N}_T(2,1)$ ; $\mathcal{N}_C(3,2)$
  
- Binaire :

  $\mathcal{B}_T(0.65)$ ; $\mathcal{B}_C(0.3)$

```{r, echo = FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  
U = runif(2*n) 

lambdaT = 1
kT = 2


Z = ifelse(arm == "T", 1, 0)
beta = -2

prob_T = 0.65
prob_C = 0.3

mean_T = 2
mean_C = 3
sd_T = 1
sd_C = 2

  
Time_1 = round((-log(1 - U)) / (lambdaT * exp(beta * Z)^(1 / kT)),3)
fup_censureT = round(rweibull(2*n, shape = 1, scale =3),3)

Time_T = pmin(Time_1, fup_censureT)
deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(3,2,1),
    summary.print = FALSE
  )

win_edp3 = sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp3 = 4*2500-(win_edp3+loose_edp3)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp3-(loose_edp2+win_edp2)

win_edp1=sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp1=tie_edp2-sum(win_edp1+loose_edp1)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_3_C (tte)", "Y_1_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_3_T (tte)", "Y_1_T (continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val5_2_1=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)


```

```{r, echo=FALSE}
summary_df5_2_1 <- summ_val5_2_1 %>% as.data.frame()
summary_df5_2_1 <- summary_df5_2_1 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

g1 <- tableGrob(summary_df5_2_1)
g2 <- tableGrob(summary_df5_1_1[,-1])

# Ajoute les titres au-dessus des tableaux
title1 <- textGrob("Résumé - Cox, tau=2, outcome principal continue C>>T", gp = gpar(fontsize = 12, fontface = "bold"))
title2 <- textGrob("Résumé - Cox, tau=2, outcome continue C>>T en 3ème", gp = gpar(fontsize = 12, fontface = "bold"))

# Combine titre + tableau pour chaque colonne
g1_full <- arrangeGrob(title1, g1, ncol = 1, heights = c(0.2, 1))
g2_full <- arrangeGrob(title2, g2, ncol = 1, heights = c(0.2, 1))

# Affiche côte à côte
space <- nullGrob() 
grid.arrange(g1_full, space, g2_full, ncol = 3, widths = c(1, 0.2, 1))
```


### HR non-constant (modèle AFT)

Ici les paramètres $\lambda$ et $k$ voudront respectivement 0.12 et 0.9, et $\beta = 2.5$.

```{r, echo=FALSE}

n_sim = 2000
n=200


nb_core = parallel::detectCores() - 2
cl = makeCluster(nb_core)
registerDoParallel(cl)
count = 0
start_time = Sys.time()

results = foreach(s = 1:n_sim, .combine = rbind, .packages = c("dplyr", "survival", "parallel", "foreach", "doParallel", "WINS"), .export = c("win.stat")) %dopar% {
  set.seed(s)
  
id=1:(2*n) 
arm=rep(c("T","C"), each=200)
  


prob_T = 0.65
prob_C = 0.3

mean_T = 2
mean_C = 3
sd_T = 1
sd_C = 2


U = runif(2*n) 
lambdaT = 0.12
kT = 0.9


Z = ifelse(arm == "T", 1, 0)
beta = 2.5


Time_1 = round((((1/(1-U)-1)*(1/lambdaT))^(1/kT)*exp(Z*beta)), 3)
fup_censureT = round(rweibull(2*n, shape = 1.5, scale =5.5),3)


Time_T = pmin(Time_1, fup_censureT)

deltaT=as.numeric(fup_censureT==Time_T)

Y_2_T=as.numeric(gener_binom(prob = prob_T)[,1] )-1
Y_2_C=as.numeric(gener_binom(prob = prob_C)[,1] )-1

Y_3_T= gener_continue(mean = mean_T, sd = sd_T)
Y_3_C= gener_continue(mean = mean_C, sd = sd_C)

stratum=sample(rep(c(1,3,5,8), each = 50))
dataT=data.frame(Y_1 = Time_T[Z==1], Delta_1 = deltaT[Z==1], Y_2 = Y_2_T, Y_3 = Y_3_T, stratum = stratum)
dataC=data.frame(Y_1 = Time_T[Z==0], Delta_1 = deltaT[Z==0], Y_2 = Y_2_C, Y_3 = Y_3_C, stratum = stratum)

 
data1=rbind(dataT,dataC)

summT = summary.data.frame(dataT)

min_Y_1T = as.numeric(stringr::str_extract(summT[1,1], "\\d+\\.\\d+"))
min_Y_3T = as.numeric(stringr::str_extract(summT[1,4], "\\d+\\.\\d+"))

nb_0_C=sum(Y_2_C==0)
nb_1_C=sum(Y_2_C==1)

nb_0_T=sum(Y_2_T==0)
nb_1_T=sum(Y_2_T==1)

median_Y_1T = as.numeric(stringr::str_extract( summT[3,1], "\\d+\\.\\d+"))
median_Y_3T = as.numeric(stringr::str_extract( summT[3,4], "\\d+\\.\\d+"))

max_Y_1T =as.numeric(stringr::str_extract(summT[6,1], "\\d+\\.\\d+"))
max_Y_3T =as.numeric(stringr::str_extract(summT[6,4], "\\d+\\.\\d+"))

summC = summary.data.frame(dataC)

min_Y_1C = as.numeric(stringr::str_extract(summC[1,1], "\\d+\\.\\d+"))
min_Y_3C = as.numeric(stringr::str_extract(summC[1,4], "\\d+\\.\\d+"))


median_Y_1C = as.numeric(stringr::str_extract( summC[3,1], "\\d+\\.\\d+"))
median_Y_3C = as.numeric(stringr::str_extract( summC[3,4], "\\d+\\.\\d+"))

max_Y_1C =as.numeric(stringr::str_extract(summC[6,1], "\\d+\\.\\d+"))
max_Y_3C =as.numeric(stringr::str_extract(summC[6,4], "\\d+\\.\\d+"))

censure_rateT=sum(dataT$Delta_1==0)/n 
censure_rateC=sum(dataC$Delta_1==0)/n 

data=data.frame(id=id, arm = arm, Y_1= data1[,1],Delta_1=data1[,2], Y_2 = data1[,3], Y_3 = data1[,4], stratum = data1[,5] )

result =
  win.stat(
    data = data,
    ep_type = c("tte", "binary", "continuous"),
    stratum.weight = "equal",
    tau = c(2,0,2),
    arm.name = c("T", "C"),
    alpha = 0.05,
    digit = 3,
    pvalue = "two-sided",
    priority = c(3,2,1),
    summary.print = FALSE
  )

win_edp3 = sum(result$summary_ep$Trt_Endpoint1[,2])
loose_edp3 = sum(result$summary_ep$Con_Endpoint1[,2])
tie_edp3 = 4*2500-(win_edp3+loose_edp3)

win_edp2=sum(result$summary_ep$Trt_Endpoint2[,2])
loose_edp2=sum(result$summary_ep$Con_Endpoint2[,2])
tie_edp2=tie_edp3-(loose_edp2+win_edp2)

win_edp1=sum(result$summary_ep$Trt_Endpoint3[,2])
loose_edp1=sum(result$summary_ep$Con_Endpoint3[,2])
tie_edp1=tie_edp2-sum(win_edp1+loose_edp1)


  count = count + 1
  write.table(c(count), file="../output.txt", append = T, col.names = F)
  
  val_GPC = result$Win_statistic$Net_Benefit[1]
  val_WR  = result$Win_statistic$Win_Ratio[1]
  val_WO  = result$Win_statistic$Win_Odds[1]
  
  p_val_GPC = result$p_value[2]
  p_val_WR  = result$p_value[1]
  p_val_WO  = result$p_value[3]
  
  return(unname(c(val_GPC,val_WR,val_WO,win_edp1,loose_edp1,tie_edp1,win_edp2,loose_edp2,tie_edp2,win_edp3,loose_edp3,tie_edp3,min_Y_1C, min_Y_3C,max_Y_1C, max_Y_3C,median_Y_1C, median_Y_3C,min_Y_1T, min_Y_3T,max_Y_1T, max_Y_3T,median_Y_1T, median_Y_3T,nb_0_C,nb_1_C,nb_0_T,nb_1_T, censure_rateC, censure_rateT, p_val_GPC, p_val_WR, p_val_WO)))
}
stopCluster(cl)
end_time = Sys.time()
execution_time = end_time - start_time

results_df = as.data.frame(results)


min_Y_1C=mean(as.numeric(results_df[,13]))
min_Y_3C=mean(as.numeric(results_df[,14]))

max_Y_1C=mean(as.numeric(results_df[,15]))
max_Y_3C=mean(as.numeric(results_df[,16]))

median_Y_1C=mean(as.numeric(results_df[,17]))
median_Y_3C=mean(as.numeric(results_df[,18]))

min_Y_1T=mean(as.numeric(results_df[,19]))
min_Y_3T=mean(as.numeric(results_df[,20]))

max_Y_1T=mean(as.numeric(results_df[,21]))
max_Y_3T=mean(as.numeric(results_df[,22]))

median_Y_1T=mean(as.numeric(results_df[,23]))
median_Y_3T=mean(as.numeric(results_df[,24]))

nb_O_C = mean(as.numeric(results_df[,25]))
nb_1_C = mean(as.numeric(results_df[,26]))

nb_0_T= mean(as.numeric(results_df[,27]))
nb_1_T = mean(as.numeric(results_df[,28]))

censure_rateC= mean(as.numeric(results_df[,29]))
censure_rateT= mean(as.numeric(results_df[,30]))

dfC=data.frame(row.names = c("min", "median", "max"), c(min_Y_1C, median_Y_1C, max_Y_1C),c(min_Y_3C, median_Y_3C, max_Y_3C))
colnames(dfC) = c("Y_3_C (tte)", "Y_1_C (continue)")
dfT=data.frame(row.names = c("min", "median", "max"), c(min_Y_1T, median_Y_1T, max_Y_1T),c(min_Y_3T, median_Y_3T, max_Y_3T))
colnames(dfT) = c("Y_3_T (tte)", "Y_1_T (continue)")

df2 = data.frame(row.name = c("0", "1"), c(nb_O_C,nb_0_T), c(nb_1_C,nb_1_T))

p_valGPC = results_df[,31]
p_valWR = results_df[,32]
p_valWO = results_df[,33]

nb_pval_GPC = sum(p_valGPC< 0.05)
nb_pval_WR = sum(p_valWR< 0.05)
nb_pval_WO = sum(p_valWO< 0.05)

colnames(df2)=c(" ","C", "T")

GPC=as.numeric(results_df[,1])
WR= as.numeric(results_df[,2])
WO= as.numeric(results_df[,3])


quantileGPC_lwr=quantile(GPC, 0.025)
quantileGPC_upr=quantile(GPC, 0.975)
étendue_GPC= round(quantileGPC_upr - quantileGPC_lwr,4)

quantileWR_lwr=quantile(WR, 0.025)
quantileWR_upr=quantile(WR, 0.975)
étendue_WR= round(quantileWR_upr - quantileWR_lwr,4)

quantileWO_lwr=quantile(WO, 0.025)
quantileWO_upr=quantile(WO, 0.975)
étendue_WO= round(quantileWO_upr - quantileWO_lwr,4)



Win   = round(c(mean(as.numeric(results_df[,10])), mean(as.numeric(results_df[,7])), mean(as.numeric(results_df[,4])), mean(as.numeric(results_df[,4])) + mean(as.numeric(results_df[,7])) +mean(as.numeric(results_df[,10])) ))

Loose = round(c(mean(as.numeric(results_df[,11])), mean(as.numeric(results_df[,8])),mean(as.numeric(results_df[,5])), mean(as.numeric(results_df[,5]))+mean(as.numeric(results_df[,8])) +mean(as.numeric(results_df[,11])) ))

Tie   = round(c(mean(as.numeric(results_df[,12])), mean(as.numeric(results_df[,9])), mean(as.numeric(results_df[,6])), mean(as.numeric(results_df[,12])) ))

df3 = data.frame(
  row.names = c("endpoint1", "endpoint2",  "endpoint3","overall"),
  Win   = Win,
  Loose = Loose,
  Tie   = Tie,
  WR = round(Win/Loose,5),
  WO = round((Win+0.5*Tie)/(Loose+0.5*Tie),5),
  GPC = round((Win-Loose)/(Win+Loose+Tie),5)
)
list(Count = df3, value_tte_cont_C = dfC, value_tte_cont_T = dfT, value_binary = df2, censure_rate_T = censure_rateT, censure_rate_C = censure_rateC, p_val_GPC = paste("probabilité d'avoir des p-valeur < 0.05 pour la GPC: ", nb_pval_GPC/n_sim), p_val_WR =  paste("probabilité d'avoir des p-valeur < 0.05 pour le WR: ", nb_pval_WR/n_sim), p_val_WO = paste("probabilité d'avoir des p-valeur < 0.05 pour le WO: ", nb_pval_WO/n_sim))

vlines = data.frame(
    method = c("GPC", "WR", "WO"),
    intercept = c(0, 1, 1),
    linetype_label = "Hypothèse H0")


val1=unlist(results_df[,1:3]$V1)
val2=unlist(results_df[,1:3]$V2)
val3=unlist(results_df[,1:3]$V3)
val=as.data.frame(unname(cbind(val1,val2,val3)))
colnames(val)=c("val_GPC","val_WR","val_WO")
summ_val5_2_2=summary(val)

 values_long = val %>%
   select(starts_with("val_")) %>%
   pivot_longer(cols = everything(), names_to = "method", values_to = "value") %>%
   mutate(method = recode(method,
                          "val_GPC" = "GPC",
                          "val_WR"  = "WR",
                          "val_WO"  = "WO"))
 values_long$value = unlist(values_long$value)
 values_long <- values_long %>% filter(!is.infinite(value))


ggplot(values_long, aes(x = value, fill = method)) +
   geom_density(alpha = 0.6, color = "black") +
   geom_vline(data = vlines, aes(xintercept = intercept, linetype = linetype_label),
              color = "black", lwd = 1) +
   theme_minimal() +
   labs(title = "Distribution des statistiques de test",
        x = "Valeur", y = "Densité") +
   scale_linetype_manual(name = "", values = c("Hypothèse H0" = "dashed")) +
   scale_fill_manual(values = c("orange",  "purple", "cyan")) +
  annotate("text", x = 4.5, y = 1.6, label = paste("Étendue GPC : ", étendue_GPC), color = "orange", hjust = 1) +
  annotate("text", x = 4.5, y = 2.35, label = paste("Étendue WR : ", étendue_WR), color = "cyan", hjust = 1) +
  annotate("text", x = 4.5, y = 3.1, label = paste("Étendue WO : ", étendue_WO), color = "purple", hjust = 1)

```

```{r, echo=FALSE}
summary_df5_2_2 <- summ_val5_2_2 %>% as.data.frame()
summary_df5_2_2 <- summary_df5_2_2 %>%
  mutate(
    Stat = stringr::str_trim(stringr::str_extract(Freq, "^[^:]+")), 
    Value = as.numeric(stringr::str_trim(stringr::str_extract(Freq, "(?<=:).*"))),
    Var2 = as.character(Var2)
  ) %>%
  select(Stat, Var2, Value) %>%
  pivot_wider(names_from = Var2, values_from = Value) %>%
  filter(!is.na(Stat))

g1 <- tableGrob(summary_df5_2_2)
g2 <- tableGrob(summary_df5_1_2[,-1])

# Ajoute les titres au-dessus des tableaux
title1 <- textGrob("Résumé - AFT, tau=2, outcome principal continue C>>T", gp = gpar(fontsize = 12, fontface = "bold"))
title2 <- textGrob("Résumé - AFT, tau=2, outcome continue C>>T en 3ème", gp = gpar(fontsize = 12, fontface = "bold"))

# Combine titre + tableau pour chaque colonne
g1_full <- arrangeGrob(title1, g1, ncol = 1, heights = c(0.2, 1))
g2_full <- arrangeGrob(title2, g2, ncol = 1, heights = c(0.2, 1))

# Affiche côte à côte
space <- nullGrob()  
grid.arrange(g1_full, space, g2_full, ncol = 3, widths = c(1, 0.2, 1))
```

